{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from pybtex.database import BibliographyData, Entry\n",
    "from pybtex.utils import OrderedCaseInsensitiveDict\n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"conferences\": {\n",
    "        \"file\" : \"biblio_c.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"\",\n",
    "        \"collection\" : {\"name\":\"publ_conferences\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"journals\":{\n",
    "        \"file\": \"biblio_j.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publ_journals\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    },\n",
    "    \"workshops\":{\n",
    "        \"file\": \"biblio_w.bib\",\n",
    "        \"venuekey\" : [\"journal\", \"booktitle\"],\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publ_workshops\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    },\n",
    "    \"book\":{\n",
    "        \"file\": \"biblio_b.bib\",\n",
    "        \"venuekey\" : [\"journal\", \"booktitle\"],\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publ_preparation\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    }, \n",
    "    \"abstract\":{\n",
    "        \"file\": \"biblio_a.bib\",\n",
    "        \"venuekey\" : [\"journal\", \"booktitle\"],\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publ_preparation\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    }, \n",
    "    \"thesis\":{\n",
    "        \"file\": \"biblio_t.bib\",\n",
    "        \"venuekey\" : [\"school\"],\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publ_preparation\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    },\n",
    "    \"preparation\":{\n",
    "        \"file\": \"biblio_u.bib\",\n",
    "        \"venuekey\" : [\"journal\", \"booktitle\"],\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publ_preparation\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)\n",
    "\n",
    "def all_escape(text):\n",
    "    return text.replace('\\\\textbf', '').replace('\\%', '%'). replace('{', '').replace('}', '').replace('\\\\emph', '').replace('\\\\quotes', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metelli2017compatible\n",
      "SUCESSFULLY PARSED metelli2017compatible: \" Compatible Reward Inverse Reinforcement Learning  \"\n",
      "metelli2018configurable\n",
      "SUCESSFULLY PARSED metelli2018configurable: \" Configurable Markov Decision Processes  \"\n",
      "metelli2018policy\n",
      "SUCESSFULLY PARSED metelli2018policy: \" Policy Optimization via Importance Sampling  \"\n",
      "papini2019optimistic\n",
      "SUCESSFULLY PARSED papini2019optimistic: \" Optimistic Policy Optimization via Multiple Importance Sampl ... \"\n",
      "metelli2019reinforcement\n",
      "SUCESSFULLY PARSED metelli2019reinforcement: \" Reinforcement Learning in Configurable Continuous Environmen ... \"\n",
      "beraha2019feature\n",
      "SUCESSFULLY PARSED beraha2019feature: \" Feature Selection via Mutual Information: New Theoretical In ... \"\n",
      "metelli2019propagating\n",
      "SUCESSFULLY PARSED metelli2019propagating: \" Propagating Uncertainty in Reinforcement Learning via Wasser ... \"\n",
      "doro2020gradient\n",
      "SUCESSFULLY PARSED doro2020gradient: \" Gradient-Aware Model-Based Policy Search  \"\n",
      "ramponi2020truly\n",
      "SUCESSFULLY PARSED ramponi2020truly: \" Truly Batch Model-Free Inverse Reinforcement Learning about  ... \"\n",
      "metelli2020control\n",
      "SUCESSFULLY PARSED metelli2020control: \" Control Frequency Adaptation via Action Persistence in Batch ... \"\n",
      "metelli2021policy\n",
      "SUCESSFULLY PARSED metelli2021policy: \" Policy Optimization as Online Learning with Mediator Feedbac ... \"\n",
      "metelli2021provably\n",
      "SUCESSFULLY PARSED metelli2021provably: \" Provably Efficient Learning of Transferable Rewards  \"\n",
      "metelli2021learning\n",
      "SUCESSFULLY PARSED metelli2021learning: \" Learning in Non-Cooperative Configurable Markov Decision Pro ... \"\n",
      "metelli2021subgaussian\n",
      "SUCESSFULLY PARSED metelli2021subgaussian: \" Subgaussian and Differentiable Importance Sampling for Off-P ... \"\n",
      "liotet2022lifelong\n",
      "SUCESSFULLY PARSED liotet2022lifelong: \" Lifelong Hyper-Policy Optimization with Multiple Importance  ... \"\n",
      "metelli2019ongradient\n",
      "SUCESSFULLY PARSED metelli2019ongradient: \" On the use of the policy gradient and Hessian in inverse rei ... \"\n",
      "likmeta2020combining\n",
      "SUCESSFULLY PARSED likmeta2020combining: \" Combining reinforcement learning with rule-based controllers ... \"\n",
      "metelli2020importance\n",
      "SUCESSFULLY PARSED metelli2020importance: \" Importance Sampling Techniques for Policy Optimization  \"\n",
      "likmeta2021dealing\n",
      "SUCESSFULLY PARSED likmeta2021dealing: \" Dealing with multiple experts and non-stationarity in invers ... \"\n",
      "metelli2018safe\n",
      "SUCESSFULLY PARSED metelli2018safe: \" Safe Policy Iteration: A Monotonically Improving Approximate ... \"\n",
      "metelli2019policy\n",
      "SUCESSFULLY PARSED metelli2019policy: \" Policy Space Identification in Configurable Environments  \"\n",
      "bianchi2017content\n",
      "SUCESSFULLY PARSED bianchi2017content: \" Content-Based Approaches for Cold-Start Job Recommendations  \"\n",
      "metelli2018configurableWorkshop\n",
      "SUCESSFULLY PARSED metelli2018configurableWorkshop: \" Configurable Markov Decision Processes  \"\n",
      "doro2019gradientWorkshop\n",
      "SUCESSFULLY PARSED doro2019gradientWorkshop: \" Gradient-Aware Model-based Policy Search  \"\n",
      "likmeta2020autonomous\n",
      "SUCESSFULLY PARSED likmeta2020autonomous: \" Autonomous Driving with Reinforcement Learning and Rule-base ... \"\n",
      "likmeta2020handling\n",
      "SUCESSFULLY PARSED likmeta2020handling: \" Handling Non-Stationary Experts in Inverse Reinforcement Lea ... \"\n",
      "ramponi2021online\n",
      "SUCESSFULLY PARSED ramponi2021online: \" Online Learning in Non-Cooperative Configurable Markov Decis ... \"\n",
      "ramponi2021efficient\n",
      "SUCESSFULLY PARSED ramponi2021efficient: \" Efficient Inverse Reinforcement Learning of Transferable Rew ... \"\n",
      "metelli2021subgaussian\n",
      "SUCESSFULLY PARSED metelli2021subgaussian: \" Subgaussian Importance Sampling for Off-Policy Evaluation an ... \"\n",
      "metelli2021optimalis\n",
      "SUCESSFULLY PARSED metelli2021optimalis: \" Policy Optimization via Optimal Policy Evaluation  \"\n",
      "metelli2022configurable\n",
      "SUCESSFULLY PARSED metelli2022configurable: \" Configurable Environments in Reinforcement Learning: An Over ... \"\n",
      "giuliani2021advancing\n",
      "SUCESSFULLY PARSED giuliani2021advancing: \" Advancing drought monitoring via feature extraction  \"\n",
      "phdthesis\n",
      "SUCESSFULLY PARSED phdthesis: \" Exploiting environment configurability in reinforcement lear ... \"\n",
      "mastersthesis\n",
      "SUCESSFULLY PARSED mastersthesis: \" Compatible reward inverse reinforcement learning  \"\n"
     ]
    },
    {
     "ename": "PybtexError",
     "evalue": "unable to open biblio_u.bib. No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pybtex/io.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(opener, filename_or_file, mode, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_existing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkpsewhich\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pybtex/io.py\u001b[0m in \u001b[0;36m_open_existing\u001b[0;34m(opener, filename, mode, locate, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'biblio_u.bib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPybtexError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-961751890436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbibtex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbibdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpubsource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#loop through the individual references in a given bibtex file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pybtex/database/input/__init__.py\u001b[0m in \u001b[0;36mparse_file\u001b[0;34m(self, filename, file_suffix)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mopen_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpybtex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_unicode\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0municode_io\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpybtex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pybtex/io.py\u001b[0m in \u001b[0;36mopen_unicode\u001b[0;34m(filename, mode, encoding)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pybtex/io.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(opener, filename_or_file, mode, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_existing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkpsewhich\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPybtexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unable to open %s. %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPybtexError\u001b[0m: unable to open biblio_u.bib. No such file or directory"
     ]
    }
   ],
   "source": [
    "exclude_keys = ['archivePrefix', \n",
    "                'acceptance', \n",
    "                'code', \n",
    "                'slides', \n",
    "                'poster', \n",
    "                'talk', \n",
    "                'supplementary', \n",
    "                'abstract', \n",
    "                'timestamp', \n",
    "                'biburl', \n",
    "                'bibsource',\n",
    "                'rankCORE',\n",
    "                'rankGGS',\n",
    "                'rankSJR']\n",
    "\n",
    "for ii, pubsource in enumerate(publist):\n",
    "    counter = 100 * ii\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    bib_ids = [bib_id for bib_id in bibdata.entries]\n",
    "    for bib_id in reversed(bib_ids):\n",
    "        \n",
    "        #print(bibdata.entries[bib_id])\n",
    "        \n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        print(bib_id)\n",
    "        \n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "\n",
    "        #todo: this hack for month and day needs some cleanup\n",
    "        if \"month\" in b.keys(): \n",
    "            if(len(b[\"month\"])<3):\n",
    "                pub_month = \"0\"+b[\"month\"]\n",
    "                pub_month = pub_month[-2:]\n",
    "            elif(b[\"month\"] not in range(12)):\n",
    "                tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                pub_month = \"{:02d}\".format(tmnth) \n",
    "            else:\n",
    "                pub_month = str(b[\"month\"])\n",
    "        if \"day\" in b.keys(): \n",
    "            pub_day = str(b[\"day\"])\n",
    "\n",
    "\n",
    "        pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "\n",
    "        #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "        clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "        url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "        url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "        counter_str = '%04d' % counter \n",
    "        counter += 1\n",
    "        md_filename = (counter_str + '-' + str(pub_year) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "        html_filename = (counter_str + '-' + str(pub_year) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "        #Build Citation from text\n",
    "        citation = \"\"\n",
    "        authors_str = \"\"\n",
    "\n",
    "        #citation authors - todo - add highlighting for primary author?\n",
    "        els = bibdata.entries[bib_id].persons[\"author\"]\n",
    "        #print(bibdata.entries[bib_id].persons[\"author\"])\n",
    "        for i, author in enumerate(els):\n",
    "            if i == len(els) - 1:\n",
    "                sep = ''\n",
    "            elif i == len(els) - 2:\n",
    "                sep = ', and '\n",
    "            else:\n",
    "                sep = ', '\n",
    "            authors_str = authors_str+\" \"+' '.join(author.first_names)+\" \"+' '.join(author.middle_names) + \" \"+' '.join(author.last_names)+ sep\n",
    "\n",
    "        #citation title\n",
    "        citation = authors_str + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "        #add venue logic depending on citation type\n",
    "        venuekeys = publist[pubsource][\"venuekey\"] if isinstance(publist[pubsource][\"venuekey\"], list) else [publist[pubsource][\"venuekey\"]]\n",
    "        for vk in venuekeys:\n",
    "            ven = b.get(vk)\n",
    "            if ven is not None:\n",
    "                break\n",
    "\n",
    "        if ven is not None:\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+ven.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "        else:\n",
    "            venue = \"\"\n",
    "\n",
    "\n",
    "        html_escaped_venue = html_escape(venue)\n",
    "        citation = citation + \" \" + html_escaped_venue\n",
    "        if len(html_escaped_venue) > 0 and pub_year != '1900':\n",
    "            citation = citation + \", \" + pub_year\n",
    "        elif len(html_escaped_venue) == 0 and pub_year != '1900':\n",
    "            citation = citation + pub_year\n",
    "\n",
    "\n",
    "        ## YAML variables\n",
    "        md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "\n",
    "        md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "        md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "\n",
    "        note = False\n",
    "        if \"note\" in b.keys():\n",
    "            if len(str(b[\"note\"])) > 5:\n",
    "                md += \"\\nnote: '\" + all_escape(html_escape(b[\"note\"])) + \"'\"\n",
    "                note = True\n",
    "\n",
    "        acceptance = False\n",
    "        if \"acceptance\" in b.keys():\n",
    "            if len(str(b[\"acceptance\"])) > 5:\n",
    "                md += \"\\nacceptance: '\" + all_escape(html_escape(b[\"acceptance\"])) + \"'\"\n",
    "                acceptance = True\n",
    "\n",
    "        if 'rankCORE' in b.keys():\n",
    "            md += \"\\nrankCORE: '\" + all_escape(html_escape(b[\"rankCORE\"])) + \"'\"\n",
    "            \n",
    "        if 'rankSJR' in b.keys():\n",
    "            md += \"\\nrankSJR: '\" + all_escape(html_escape(b[\"rankSJR\"])) + \"'\"\n",
    "            \n",
    "        if 'rankGGS' in b.keys():\n",
    "            md += \"\\nrankGGS: '\" + all_escape(html_escape(b[\"rankGGS\"])) + \"'\"\n",
    "\n",
    "\n",
    "        #print(b.keys())\n",
    "        abstract = False\n",
    "        if \"abstract\" in b.keys():\n",
    "            if len(str(b[\"abstract\"])) > 5:\n",
    "                abstract = True\n",
    "\n",
    "        md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "        md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "\n",
    "        url = False\n",
    "        if \"url\" in b.keys():\n",
    "            if len(str(b[\"url\"])) > 5:\n",
    "                md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                url = True\n",
    "\n",
    "        md += \"\\npubtype: '\" + html_escape(pubsource) + \"'\"\n",
    "\n",
    "        md += \"\\nauthors: '\" + html_escape(authors_str) + \"'\"\n",
    "        md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "\n",
    "        #Bibtex entry\n",
    "\n",
    "        this_entry = copy.deepcopy(bibdata.entries[bib_id])\n",
    "        this_entry.fields =  OrderedCaseInsensitiveDict((key, this_entry.fields[key]) for key in this_entry.fields.keys() if key not in exclude_keys)\n",
    "\n",
    "        new_bib_data = BibliographyData({bib_id : this_entry})\n",
    "\n",
    "        #print(new_bib_data.to_string('bibtex'))\n",
    "\n",
    "        new_bib_data.to_file('../files/bibtex/' + bib_id + '.bib', 'bibtex')\n",
    "\n",
    "        bib_str = new_bib_data.to_string('bibtex')\n",
    "\n",
    "        if not (pubsource == 'preparation' or (note and 'To appear' in b[\"note\"])):\n",
    "            md += \"\\nbibtexfile: '\" + \"/files/bibtex/\" + bib_id + \".bib'\"\n",
    "\n",
    "\n",
    "        md += \"\\n---\"\n",
    "\n",
    "\n",
    "        ## Markdown description for individual page\n",
    "        if abstract:\n",
    "            md += \"\\n\" + \"Abstract\\n <br> \" + html_escape(b[\"abstract\"]) + \" <br> \\n\"\n",
    "\n",
    "        if url:\n",
    "            md += \"\\n [[Link](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}] \" \n",
    "        for field in ['poster', 'slides', 'code', 'talk', 'supplementary']:\n",
    "            if field in b.keys():\n",
    "                if len(str(b[field])) > 5:\n",
    "                    md += \"[[\" + field.capitalize() + \"](\" + b[field] + \"){:target=\\\"_blank\\\"}] \" \n",
    "\n",
    "        #else:\n",
    "        #    md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "        if not (pubsource == 'preparation' or (note and 'To appear' in b[\"note\"])):\n",
    "            md += \"[[BibTeX](\" + \"/files/bibtex/\" + bib_id  + \".bib\" +\"){:target=\\\"_blank\\\"}] \" \n",
    "            md += \"\\n\" + \"<pre> \" + bib_str[:-1] + \" </pre>\" + \"\\n\"\n",
    "            #md += \"\\n\" + \"<input type=\\\"hidden\\\" id=\\\"bibtex\\\" name=\\\"bibtex\\\" value=\\\"\"+ \"Vediamo\" + \"\\\">\"\n",
    "            #md += \"<button class=\\\"btn btn-primary\\\" type=\\\"copyToClipboard('#bibtex')\\\">Copy BibTeX</button>\"\n",
    "\n",
    "        md_filename = os.path.basename(md_filename)\n",
    "\n",
    "\n",
    "\n",
    "        with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "            f.write(md)\n",
    "        print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "    # field may not exist for a reference\n",
    "        \n",
    "    counter += 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
